name: Daily Review Scraper

on:
  schedule:
    - cron: '0 2 * * *'   # Setiap hari jam 02:00 UTC (09:00 WIB)
  workflow_dispatch:       # Bisa dijalankan manual dari GitHub UI

jobs:
  run-script:
    runs-on: ubuntu-latest

    steps:
      # --- 1️⃣ Checkout repository ---
      - name: Checkout repository
        uses: actions/checkout@v4

      # --- 2️⃣ Set up Python environment ---
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      # --- 3️⃣ Install dependencies ---
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install google-play-scraper requests pandas gspread google-auth gdown google-auth-oauthlib google-auth-httplib2 google-api-python-client pytz

      # --- 4️⃣ Jalankan data_scrapping.py ---
      - name: Run scraper
        env:
          SPREADSHEET_ID: ${{ secrets.SPREADSHEET_ID }}
          GDRIVE_CREDENTIAL_JSON: ${{ secrets.GDRIVE_CREDENTIAL_JSON }}
        run: |
          echo "$GDRIVE_CREDENTIAL_JSON" > ifg-credentials.json
          python data_scrapping.py

      # --- 5️⃣ Jalankan data_clean.py (merge, cleaning, remove emoji, normalisasi waktu, dll) ---
      - name: Run data cleaner
        env:
          SPREADSHEET_ID: ${{ secrets.SPREADSHEET_ID }}
          GDRIVE_CREDENTIAL_JSON: ${{ secrets.GDRIVE_CREDENTIAL_JSON }}
        run: |
          echo "$GDRIVE_CREDENTIAL_JSON" > ifg-credentials.json
          python data_clean.py
